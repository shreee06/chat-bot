# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BqQwmemtowZgkU8v8F7FekujTDb9uore
"""

!pip install tensorflow

import tensorflow as tf
import numpy as np

# Define training data
questions = ["What is your name?", "How are you?", "What are you doing?"]
answers = ["My name is Chatbot.", "I'm fine, thank you.", "I'm chatting with you."]

# Tokenize the training data
tokenizer = tf.keras.preprocessing.text.Tokenizer()
tokenizer.fit_on_texts(questions + answers)
question_sequences = tokenizer.texts_to_sequences(questions)
answer_sequences = tokenizer.texts_to_sequences(answers)

# Pad the sequences to ensure consistent length
max_sequence_length = max(map(len, question_sequences + answer_sequences))
question_sequences = tf.keras.preprocessing.sequence.pad_sequences(question_sequences, maxlen=max_sequence_length)
answer_sequences = tf.keras.preprocessing.sequence.pad_sequences(answer_sequences, maxlen=max_sequence_length)

# Define the chatbot model
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(len(tokenizer.word_index) + 1, 128, input_length=max_sequence_length),
    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True)),
    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128)),
    tf.keras.layers.Dense(len(tokenizer.word_index) + 1, activation="softmax")
])

# Compile the model
model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

# Train the model
model.fit(question_sequences, np.argmax(answer_sequences, axis=-1), epochs=10)

# Start a conversation with the chatbot
while True:
    user_input = input("You: ")

    # Preprocess the user input
    user_sequence = tokenizer.texts_to_sequences([user_input])
    user_sequence = tf.keras.preprocessing.sequence.pad_sequences(user_sequence, maxlen=max_sequence_length)

    # Get the predicted response from the chatbot model
    predicted_sequence = model.predict(user_sequence)
    predicted_indices = np.argsort(predicted_sequence[0])[-3:][::-1]  # Get top 3 predicted indices
    bot_responses = [tokenizer.index_word.get(idx, "") for idx in predicted_indices if idx != 0]

    print("ChatBot:")
    for response in bot_responses:
        print(response)